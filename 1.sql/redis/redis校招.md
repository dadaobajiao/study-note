# Redis

## 为什么使用Redis 

用缓存，主要有两个用途：**高性能**、**高并发**。

### 高性能

假设这么个场景，你有个操作，一个请求过来，吭哧吭哧你各种乱七八糟操作 mysql，半天查出来一个结果，耗时 600ms。但是这个结果可能接下来几个小时都不会变了，或者变了也可以不用立即反馈给用户。那么此时咋办？

缓存啊，折腾 600ms 查出来的结果，扔缓存里，一个 key 对应一个 value，下次再有人查，别走 mysql 折腾 600ms 了，直接从缓存里，通过一个 key 查出来一个 value，2ms 搞定。性能提升 300 倍。

就是说对于一些需要复杂操作耗时查出来的结果，且确定后面不怎么变化，但是有很多读请求，那么直接将查询出来的结果放在缓存中，后面直接读缓存就好。

### 高并发

mysql 这么重的数据库，压根儿设计不是让你玩儿高并发的，虽然也可以玩儿，但是天然支持不好。mysql 单机支撑到 `2000QPS` 也开始容易报警了。

所以要是你有个系统，高峰期一秒钟过来的请求有 1 万，那一个 mysql 单机绝对会死掉。你这个时候就只能上缓存，把很多数据放缓存，别放 mysql。缓存功能简单，说白了就是 `key-value` 式操作，单机支撑的并发量轻松一秒几万十几万，支撑高并发 so easy。单机承载并发量是 mysql 单机的几十倍。

> 缓存是走内存的，内存天然就支撑高并发。



## 分布式缓存和本地缓存有啥区别



1. 缓存分为本地缓存和分布式缓存。以 Java 为例，使用自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。
2. 使用 redis 或 memcached 之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。缺点是需要保持 redis 或 memcached服务的高可用，整个程序架构上较为复杂。





## redis和Memecache的区别  

1. redis 支持更丰富的数据类型（支持更复杂的应用场景），Memcached 只支持最简单的 k/v 数据类型
2. Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memecache 把数据全部存在内存之中。
3. redis 目前是原生支持 cluster 模式的，而Memecache原生不支持集群。
4. Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型。
5. Redis 支持发布订阅模型、Lua脚本、事务等功能，而Memcached不支持。并且，Redis支持更多的编程语言。

## redis常用数据结构和使用场景  

### 字符串String

**使用场景：**

- 缓存，用于支持高并发
- 计数器，视频播放数
- 限速，处于安全考虑，每次进行登录时让用户输入手机验证码，为了短信接口不被频繁访问，会限制用户每分钟获取验证码的频率。就是设置过期时间

### 列表list

**使用场景：**

- 文章列表，每个用户都有属于自己的文章列表，现在需要分页展示文章列表，此时可以考虑使用列表，列表不但有序，同时支持按照索引范围获取元素。(lrange命令)
- 消息队列，使用列表技巧：
  * lpush+lpop=Stack(栈)
  * lpush+rpop=Queue（队列）
  * lpush+ltrim=Capped Collection（有限集合）
  * lpush+brpop=Message Queue（消息队列）
- 时间轴

### 字典hash

**使用场景：**

- 记录帖子的点赞数、评论数和点击数。帖子的标题、摘要、作者和封面信息，用于列表页展示
- 用户信息管理，key是用户标识，value是用户信息。hash 特别适合用于存储对象

### 集合set

**使用场景：**

- 标签（tag），集合类型比较典型的使用场景，如一个用户对娱乐、体育比较感兴趣，另一个可能对新闻感兴 趣，这些兴趣就是标签，有了这些数据就可以得到同一标签的人，以及用户的共同爱好的标签。

### 有序集合zset

- 排行榜，记录热榜帖子 ID 列表，总热榜和分类热榜



### HyperLogLog

统计网页的uv(**独立访客，每个用户每天只记录一次**)，如果用SET的话空间耗费会很大

pv(**浏览量，用户每点一次记录一次**)可以用String来统计

## Zset底层实现？跳表搜索插入删除过程？  

> - 读的这篇文章：https://mp.weixin.qq.com/s/NOsXdrMrWwq4NTm180a6vw
>
> - 总结的时候参考了这些文章：
>
>   - https://juejin.im/book/5afc2e5f6fb9a07a9b362527/section/5b5ac63d5188256255299d9c
>   - http://zhangtielei.com/posts/blog-redis-skiplist.html
>
> - 什么是跨度：https://www.cnblogs.com/handwrit2000/p/12626570.html
>
> - 下面是总结了一下

### Zset底层实现？

跳跃表

### 跳表搜索插入删除过程?

#### 搜索过程：

   假设我们需要查找的值为k(score)

1. 需要从 header 的当前最高层maxLevel开始遍历，直到找到 最后一个比k小的节点
2. 然后从这个节点开始降一层再遍历找到第二个节点 (最后一个比k小的节点)，
3. 然后以此类推一直降到最底层进行遍历就找到了期望的节点 。

**注意：**

1. 不是和当前元素比较,是和当前元素的下一元素比较，所以才能知道(最后一个比k小的元素)
2. redis跳跃表的排序是首先比较score,如果score相等，还需要比较value

#### 插入过程：

1. 首先是有一个搜索确定位置的过程，逐步降级寻找目标节点，得到「搜索路径」

2. 然后才开始插入

   2-1. 为每个节点随机出一个层数(level)

   2-2. 创建新节点，再将搜索路径上的节点和这个新节点通过前向后向指针串起来

   2-3. 如果分配的新节点的高度高于当前跳跃列表的最大高度，更新一下跳跃列表的最大高度，并且填充跨度

   

#### 删除过程：

删除过程和插入过程类似，都需先把这个「搜索路径」找出来。然后对于每个层的相关节点都重排一下前向后向指针就可以了。同时还要注意更新一下最高层数`maxLevel`。



#### 更新过程

1. 当我们调用 `ZADD` 方法时，如果对应的 value 不存在，那就是插入过程，如果这个 value 已经存在，只是调整一下 score 的值，那就需要走一个更新流程。
2. 假设这个新的 score 值并不会带来排序上的变化，那么就不需要调整位置，直接修改元素的 score 值就可以了，
3. 但是如果排序位置改变了，那就需要调整位置。Redis 采用了一个非常简单的策略，**把这个元素删除再插入这个**，需要经过两次路径搜索，从这一点上来看，Redis 的 `ZADD` 代码似乎还有进一步优化的空间。



#### 元素排名的实现

1. 跳跃表本身是有序的，Redis 在 skiplist 的 forward 指针上进行了优化，给每一个 forward 指针都增加了 跨度`span` 属性，用来 **记录了前进指针所指向节点和当前节点的距离(也就是跨过了几个节点)**。在源码中我们也可以看到 Redis 在插入、删除操作时都会小心翼翼地更新 `span` 值的大小。
2. 所以，沿着 **"搜索路径"**，把所有经过节点的跨度 `span` 值进行累加就可以算出当前元素的最终 rank 值了。



## redis过期淘汰策略  

> 这个讲得好：https://doocs.gitee.io/advanced-java/#/./docs/high-concurrency/redis-expiration-policies-and-lru

**补充：**

1. **volatile-lfu**：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰
2. **allkeys-lfu**：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key

### lru和lfu区别



- LRU，即：最近最少使用淘汰算法（Least Recently Used）。LRU是淘汰一段时间内，没有被使用的页面。

- LFU，即：最不经常使用淘汰算法（Least Frequently Used）。LFU是淘汰一段时间内，使用次数最少的页面。

## redis持久化机制？都有什么优缺点？持久化的时候还能接受请求吗？  

> 参考：
>
> - JavaGuide-Redis常见问题总结
> - https://mp.weixin.qq.com/s/O_qDco6-Dasu3RomWIK_Ig
> - https://juejin.im/book/5afc2e5f6fb9a07a9b362527/section/5afc364c6fb9a07aaf3567c8

**Redis** 的数据 **全部存储** 在 **内存** 中，如果 **突然宕机**，数据就会全部丢失，因此必须有一套机制来保证 Redis 的数据不会因为故障而丢失，这种机制就是 Redis 的 **持久化机制**，它会将内存中的数据库状态 **保存到磁盘** 中。



下面是总结

### RDB快照

1. **Redis 快照** 是最简单的 Redis 持久性模式。当满足特定条件时，它将生成数据集的时间点快照，例如，如果先前的快照是在2分钟前创建的，并且现在已经至少有 *100* 次新写入，则将创建一个新的快照。此条件可以由用户配置 Redis 实例来控制【JavaGuide里有如何配置】。快照是一次全量备份

2. 但我们知道，Redis 是一个 **单线程** 的程序，这意味着，我们不仅仅要响应用户的请求，还需要进行内存快照。而后者要求 Redis 必须进行 IO 操作，这会严重拖累服务器的性能。

3. 还有一个重要的问题是，我们在 **持久化的同时**，**内存数据结构** 还可能在 **变化**，比如一个大型的 hash 字典正在持久化，结果一个请求过来把它删除了，还没持久化完呢。怎么办呢

4. 操作系统多进程 **COW(Copy On Write) 机制**可以解决上述问题

   4-1.**Redis** 在持久化时会调用 `glibc` 的函数 `fork` 产生一个子进程，简单理解也就是基于当前进程 **复制** 了一个进程，主进程和子进程会共享内存里面的代码块和数据段

   4-2.所以 **快照持久化** 可以完全交给 **子进程** 来处理，**父进程** 则继续 **处理客户端请求**。**子进程** 做数据持久化，它 **不会修改现有的内存数据结构**，它只是对数据结构进行遍历读取，然后序列化写到磁盘中。但是 **父进程** 不一样，它必须持续服务客户端请求，然后对 **内存数据结构进行不间断的修改**

   4-3.这个时候就会使用操作系统的 COW 机制来进行 **数据段页面** 的分离。数据段是由很多操作系统的页面组合而成，当父进程对其中一个页面的数据进行修改时，会将被共享的页面复 制一份分离出来，然后 **对这个复制的页面进行修改**。这时 **子进程** 相应的页面是 **没有变化的**，还是进程产生时那一瞬间的数据。

   4-4.子进程因为数据没有变化，它能看到的内存里的数据在进程产生的一瞬间就凝固了，再也不会改变，这也是为什么 **Redis** 的持久化 **叫「快照」的原因**。接下来子进程就可以非常安心的遍历数据了进行序列化写磁盘了。



### AOF



#### AOF原理

1. **AOF(Append Only File - 仅追加文件)** 它的工作方式非常简单：每次执行 **修改内存** 中数据集的写操作时，都会 **记录** 该操作。假设 AOF 日志记录了自 Redis 实例创建以来 **所有的修改性指令序列**，那么就可以通过对一个空的 Redis 实例 **顺序执行所有的指令**，也就是 **「重放」**，来恢复 Redis 当前实例的内存数据结构的状态。
2. 当 Redis 收到客户端修改指令后，会先进行参数校验、然后直接执行指令，如果没问题，就 **立即** 将该指令文本 **存储** 到 AOF 日志中，也就是说，**先执行指令再将日志存盘**。这一点不同于 `MySQL`、`LevelDB`、`HBase` 等存储引擎，如果我们先存储日志再做逻辑处理，这样就可以保证即使宕机了，我们仍然可以通过之前保存的日志恢复到之前的数据状态，但是 **Redis 为什么没有这么做呢？**
3. 引用一条来自知乎上的回答：我甚至觉得没有什么特别的原因。仅仅是因为，由于AOF文件会比较大，为了避免写入无效指令（错误指令），必须先做指令检查？如何检查，只能先执行了。因为语法级别检查并不能保证指令的有效性，比如删除一个不存在的key。而MySQL这种是因为它本身就维护了所有的表的信息，所以可以语法检查后过滤掉大部分无效指令直接记录日志，然后再执行。



#### AOF重写

1. Redis 在长期运行的过程中，AOF 的日志会越变越长。如果实例宕机重启，重放整个 AOF 日志会非常耗时，导致长时间 Redis 无法对外提供服务。所以需要对 AOF 日志瘦身。
2. AOF重写可以产生一个新的AOF文件，这个新的AOF文件和原有的AOF文件所保存的数据库状态一样，但体积更小。
3. Redis 提供了 bgrewriteaof 指令用于对 AOF 日志进行瘦身。其原理就是开辟一个子进程对内存进行遍历转换成一系列 Redis 的操作指令，序列化到一个新的 AOF 日志文件中。序列化完毕后再将操作期间发生的增量 AOF 日志追加到这个新的 AOF 日志文件中，追加完毕后就立即替代旧的 AOF 日志文件了，瘦身工作就完成了。

#### fsync

1. AOF 日志是以文件的形式存在的，当程序对 AOF 日志文件进行写操作时，实际上是将内容写到了内核为文件描述符分配的一个内存缓存中，然后内核会异步将这些数据刷回到磁盘的。这就意味着如果机器突然宕机，AOF 日志内容可能还没有来得及完全刷到磁盘中，这个时候就会出现日志丢失。那该怎么办？
2. Linux 的`glibc`提供了`fsync(int fd)`函数可以将指定文件的内容强制从内核缓存刷到磁盘。只要 Redis 进程实时调用 fsync 函数就可以保证 aof 日志不丢失。但是 fsync 是一个磁盘 IO 操作，它很慢！
3. 所以在生产环境的服务器中，Redis 通常是每隔 1s 左右执行一次 fsync 操作，周期 1s 是可以配置的。这是在数据安全性和性能之间做了一个折中，在保持高性能的同时，尽可能使得数据少丢失。



### Redis4.0混合持久化

1. 重启 Redis 时，我们很少使用 rdb 来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 rdb 来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。
2. Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——混合持久化。将 rdb 文件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是自持久化开始到持久化结束的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小。
3. 于是在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。



## redis事务  

> https://juejin.im/book/5afc2e5f6fb9a07a9b362527/section/5afc3747f265da0b71567686

### 事务简介 

1. 每个事务的操作都有 begin、commit 和 rollback，begin 指示事务的开始，commit 指示事务的提交，rollback 指示事务的回滚。Redis 在形式上看起来也差不多，分别是 multi/exec/discard。multi 指示事务的开始，exec 指示事务的执行，discard 指示事务的丢弃。
2. 所有的指令在 exec 之前不执行，而是缓存在服务器的一个事务队列中，服务器一旦收到 exec 指令，才开执行整个事务队列，执行完毕后一次性返回所有指令的运行结果。因为 Redis 的单线程特性，它不用担心自己在执行队列的时候被其它指令打搅，可以保证他们能得到的「原子性」执行。但是 Redis 的事务根本不能算「原子性」，而仅仅是满足了事务的「隔离性」，隔离性中的串行化——当前执行的事务有着不被其它事务打断的权利

### 为什么 Redis 的事务不能支持回滚？

1. redis是先执行指令，然后记录日志，如果执行失败，日志也不会记录，也就不能回滚了

### Redis 是单线程，命令是按顺序执行无并发，已经有Multi 和 Exec了为什么还需要Watch?

1. redis事务在执行时是单线程运行的。但是在执行前有可能别的客户端已经修改了事务里执行的key。所以在multi事务开始之前用watch检测这个key避免被其他客户端改变的。如果这个key被改变 了 exec的时候就会报错 不执行这个事务。

2. 这里的“other client” 并不一定是另外一个客户端，watch操作执行之后，multi之外任何操作都可以认为是other clinet在操作（即使仍然是在同一个客户端上操作），exec该事务也仍旧会失败。

   > redis使用watch实现cas具体示例：https://www.jianshu.com/p/0244a875aa26

3. 分布式锁是悲观锁，redis的watch机制是乐观锁。悲观锁的意思就是我不允许你修改。乐观锁的意思就是你修改了之后要告诉我，我让我的操作失败。



## redis是单线程还是多线程？为什么那么快？  



### 为啥 redis 单线程模型也能效率这么高？？

* 纯内存操作。
* 核心是基于非阻塞的 IO 多路复用机制。
* C 语言实现，一般来说，C 语言实现的程序“距离”操作系统更近，执行速度相对会更快。
* 单线程反而避免了多线程的频繁上下文切换问题，预防了多线程可能产生的竞争问题。

### redis的线程模型简介，及一次通信过程图解(问的概率小)

https://doocs.github.io/advanced-java/#/./docs/high-concurrency/redis-single-thread-model



## 几种IO模型

我写过这篇文章，可以翻一下

## select、poll、epoll的区别？  

> select, poll, epoll 都是I/O多路复用的具体的实现，之所以有这三个存在，其实是他们出现是有先后顺序的。
>
> - https://blog.csdn.net/nanxiaotao/article/details/90612404
> - https://www.cnblogs.com/aspirant/p/9166944.html
> - https://www.zhihu.com/question/32163005

### 1.select

1. 它仅仅知道了，有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以**select具有O(n)的无差别轮询复杂度**，同时处理的流越多，无差别轮询时间就越长。
2. 单个进程可监视的fd_set(监听的端口个数)数量被限制：32位机默认是1024个，64位机默认是2048。但可通过修改宏定义或编译内核修改句柄数量

### 2.poll

poll本质上和select没有区别，采用**链表**的方式替换原有fd_set数据结构,而使其**没有连接数的限制**。

### 3.epoll

1. epoll可以理解为event poll，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实际上是事件驱动（每个事件关联上fd）的，此时我们对这些流的操作都是有意义的。（复杂度降低到了O(1)）
2. 效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数。即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。
3. epoll通过内核和用户空间共享一块内存来实现的。select和poll都是内核需要将消息传递到用户空间，都需要内核拷贝动作
4. epoll有EPOLLLT和EPOLLET两种触发模式，也就是水平触发和边沿触发两种模式。(**暂时不去记，有个印象，大致是什么样就可以**)





## redis集群数据分布方式？有什么优点？一致性hash呢？  

>  详细看这里：https://doocs.gitee.io/advanced-java/#/./docs/high-concurrency/redis-cluster

### 分布式寻址有哪几种？

* hash 算法（大量缓存重建）
* 一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）
* redis cluster 的 hash slot 算法



### redis集群数据分布方式

redis cluster采用hash slot。(中文就是hash槽)

**优点：**

1. 任何一台机器宕机，其它节点，不影响的。因为 key 找的是 hash slot，不是机器。



### 一致性hash

思想上就是一个环，key取hash，然后顺时针找第一个节点

**优点：**

1. 如果一个节点挂了，受影响的数据仅仅是此节点到环空间前一个节点之间的数据，其它不受影响。增加一个节点也同理。

**缺点：**

1. 一致性哈希算法在节点太少时，容易因为节点分布不均匀而造成**缓存热点**的问题。为了解决这种热点问题，一致性 hash 算法引入了虚拟节点机制，即对每一个节点计算多个 hash，每个计算结果位置都放置一个虚拟节点。这样就实现了数据的均匀分布，负载均衡。



## 为什么使用跳跃表，不用平衡树,hash表



* **skiplist和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。因此，在哈希表上只能做单个key的查找，不适宜做范围查找**。所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。
* **在做范围查找的时候，平衡树比skiplist操作要复杂**。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。
* **平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。**
* 从内存占用上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。
* 查找单个key，skiplist和平衡树的时间复杂度都为O(log n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。所以我们平常使用的各种Map或dictionary结构，大都是基于哈希表实现的。
* **从算法实现难度上来比较，skiplist比平衡树要简单得多**。



## HyperLogLog(问的概率小)

> 参考：
>
> - https://mp.weixin.qq.com/s/9dtGe3d_mbbxW5FpVPDNow
> - https://juejin.im/book/5afc2e5f6fb9a07a9b362527/section/5b336548e51d4558a426ff56
>
> - https://www.jianshu.com/p/55defda6dcd2
> - https://www.baidu.com/s?wd=HyperLogLog%E5%8E%9F%E7%90%86&ie=UTF-8





## 布隆过滤器

> 整体参考：
>
> - https://juejin.im/book/5afc2e5f6fb9a07a9b362527/section/5b33657cf265da597b0f99ab
> - https://www.wmyskxz.com/2020/03/11/redis-5-yi-ji-shu-ju-guo-lu-he-bu-long-guo-lu-qi/#toc-heading-1

### 原理

> 原理：https://juejin.im/book/5afc2e5f6fb9a07a9b362527/section/5b33657cf265da597b0f99ab
>
> 看上面那篇文章的-**布隆过滤器的原理**-这部分



### 使用场景

- **大数据判断是否存在**：这就可以实现出上述的去重功能，如果你的服务器内存足够大的话，那么使用 HashMap 可能是一个不错的解决方案，理论上时间复杂度可以达到 O(1 的级别，但是当数据量起来之后，还是只能考虑布隆过滤器。
- **解决缓存穿透**：我们经常会把一些热点数据放在 Redis 中当作缓存，例如产品详情。 通常一个请求过来之后我们会先查询缓存，而不用直接读取数据库，这是提升性能最简单也是最普遍的做法，但是 **如果一直请求一个不存在的缓存**，那么此时一定不存在缓存，那就会有大量请求直接打到数据库 上，造成 **缓存穿透**，布隆过滤器也可以用来解决此类问题。
- **爬虫/ 邮箱等系统的过滤**：平时不知道你有没有注意到有一些正常的邮件也会被放进垃圾邮件目录中，这就是使用布隆过滤器误判 导致的。
- **推荐系统去重**：比如抖音的推荐系统去重，它会给我们不停地推荐新的内容，它每次推荐时要去重，去掉那些已经看过的内容。通过布隆过滤器判断是否已经看过的重复内容



### 注意事项

1. 当布隆过滤器说某个值存在时，这个值可能不存在；当它说不存在时，那就肯定不存在。
2. 使用时不要让实际元素远大于初始化大小，当实际元素开始超出初始化大小时，应该对布隆过滤器进行重建，重新分配一个 size 更大的过滤器，再将所有的历史元素批量 add 进去 (这就要求我们在其它的存储器中记录所有的历史元素)。因为 error_rate 不会因为数量超出就急剧增加，这就给我们重建过滤器提供了较为宽松的时间。





### 大致空间占用

1. 当一个元素平均需要 1 个字节 (8bit) 的指纹空间时 (l/n=8)，错误率大约为 2%
2. 错误率为 10%，一个元素需要的平均指纹空间为 4.792 个 bit，大约为 5bit
3. 错误率为 1%，一个元素需要的平均指纹空间为 9.585 个 bit，大约为 10bit
4. 错误率为 0.1%，一个元素需要的平均指纹空间为 14.377 个 bit，大约为 15bi





## 如何保证 redis 的高并发和高可用？(问的概率小)

1. redis 实现高并发主要依靠**主从架构**，一主多从，一般来说，很多项目其实就足够了，单主用来写入数据，单机几万 QPS，多从用来查询数据，多个从实例可以提供每秒 10w 的 QPS。如果想要在实现高并发的同时，容纳大量的数据，那么就需要 redis 集群，使用 redis 集群之后，可以提供每秒几十万的读写并发。
2. redis 高可用，如果是做主从架构部署，那么加上哨兵就可以了，就可以实现，任何一个实例宕机，可以进行主备切换。



## redis主从架构(问的概率小)

> https://doocs.gitee.io/advanced-java/#/./docs/high-concurrency/redis-master-slave
>
> 如果问到的话，答个大概其实就可以了



## redis哨兵机制(问的概率小)

> https://doocs.gitee.io/advanced-java/#/./docs/high-concurrency/redis-sentinel
>
> 如果问到的话，答个大概其实就可以了



## redis集群，也就是redis cluster（问的概率小）

> https://doocs.gitee.io/advanced-java/#/./docs/high-concurrency/redis-cluster

**注意redis cluster和redis replication ，redis哨兵的关系**

redis cluster 功能强大，直接集成了 replication 和 sentinel 的功能。





## 高并发环境使用缓冲会出现什么问题？



### 缓存穿透

#### 是什么：

**缓存穿透**

1. 是指查询一个一定不存在的数据，由于缓存是不命中，将去查询数据库，但是数据库也无此记录，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。
2. 举个栗子。数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。这样的话，缓存中不会有，请求每次都“**视缓存于无物**”，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。

#### 解决：

1. 会在接口层增加校验，比如用户鉴权校验，参数做校验，不合法的参数直接代码Return，比如：id 做基础校验，id <=0的直接拦截等。

2. 缓存空，但它的过期时间会很短，最长不超过五分钟。为了防止缓存穿透将，null或者空字符串值设置给redis。比如

   set -999 UNKNOWN  ,set  -1  null

3. 布隆过滤器



#### 比较新的解决办法：布隆过滤器



1、Redis还有一个高级用法**布隆过滤器（Bloom Filter）**这个也能很好的防止缓存穿透的发生，他的原理也很简单就是利用高效的数据结构和算法快速判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查了DB刷新KV再return。

2、请注意，用 redis 也可以做到判断 key 对应的value 在数据库中存不在，那就是把数据库里的所有value对应的key都储存在redis 中,而value可以为空，然后判断下`key.IsExists()`就可以了，但是这无疑会浪费大量空间，因为存储了数据库中所有的key。而且这也不符合缓存的初衷：咱不能暴力的把所有key都存下来，而是查询了啥key，我们缓存啥key。而布隆过滤器是一种非常高效的数据结构，把所有数据库的value对应的key 存储到布隆过滤器里，几乎不消耗什么空间，而且查询也是相当的快！但是请注意，它只能判断 key 是否存在（而且会有一定的误差）。所以一个查询先通过布隆顾虑器判断key是否存在(key 对应的value是否存在数据库中)，如果不存在直接返回空就好了。



### 缓存雪崩

#### 是什么：

**缓存雪崩**

1. 是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。
2. 所有缓存机器意外发生了全盘宕机。缓存挂了，此时 请求全部落数据库，数据库必然扛不住。



#### 解决：

1. 原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。
2. 事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃。
3. 事中：本地 ehcache 缓存 + hystrix 限流&降级，避免 MySQL 被打死。
4. 事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。



### 缓存击穿

#### 是什么：

对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：如果这个key在大量请求同时进来前正好失效，那么所有对这个key的数据查询都落到db，我们称为缓存击穿。



#### 解决：

不同场景下的解决方式可如下：

* 若缓存的数据是基本不会发生更新的，则可尝试将该热点数据设置为永不过期。
* 若缓存的数据更新不频繁，且缓存更新的整个流程耗时较少的情况下，则可以采用基于 redis、zookeeper 等分布式中间件的分布式互斥锁，或者本地互斥锁以保证仅少量的请求能请求数据库并重新构建缓存，其余线程则在锁释放后能访问到新缓存。
* 若缓存的数据更新频繁或者缓存更新的流程耗时较长的情况下，可以利用定时线程在缓存过期前主动的重新构建缓存或者延后缓存的过期时间，以保证所有的请求能一直访问到对应的缓存。



## 如何保证缓存与数据库的双写一致性？

> https://doocs.gitee.io/advanced-java/#/./docs/high-concurrency/redis-consistence
>
> 讲的蛮好



## LRU和LFU

> https://www.cnblogs.com/sddai/p/9739900.html

1、LRU和LFU都是内存管理的页面置换算法。 

2、LRU，即：最近最少使用淘汰算法（Least Recently Used）。LRU是淘汰最长时间没有被使用的页面。

3、LFU，即：最不经常使用淘汰算法（Least Frequently Used）。LFU是淘汰一段时间内，使用次数最少的页面。

4、LRU的意思是只要在最近用了一次这个页面，这个页面就可以不用被淘汰。LFU的意思是即使我最近用了某个页面，但是这个页面在一段时间内使用次数还是最少的话，我还是要淘汰它，相当于LFU说的是使用频率。



## 参考

> 下面是参考的比较多的，参考的比较少的直接在文中写明了

- https://github.com/doocs/advanced-java
- https://github.com/Snailclimb/JavaGuide
- [Redis 深度历险：核心原理与应用实践](https://juejin.cn/book/6844733724618129422)【不推荐】